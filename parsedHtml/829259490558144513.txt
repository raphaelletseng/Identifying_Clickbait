Twitter broadens its campaign against hate and abuse
Twitter broadens its campaign against hate and abuse
NEW YORK (AP) — Twitter announced Tuesday that it is expanding efforts to protect its users from abuse and harassment, the latest milestone in a broader, growing corporate campaign to crack down on online hate. The social media giant said it has begun identifying people who have been banned for abusive behavior and it will stop them from creating new accounts. The company said its changes, which also include a new "safe search" feature, will be implemented in the coming weeks. In July, Twitter banned conservative provocateur Milo Yiannopoulos, an editor of the right-wing news site Breitbart News, for "participating in or inciting targeted abuse of individuals." Twitter subsequently suspended the accounts of other prominent figureheads of the "alt-right" fringe movement, an amorphous mix of racism, white nationalism, xenophobia and anti-feminism. Twitter has been under fire for failing to address hate and abuse on the site since its founding a decade ago. Balancing its reputation as a free speech haven has come into conflict with efforts to protect users. Other internet companies have taken recent steps to curb abusive behavior and ban users who violate rules against promoting hate. Reddit banned a forum for white nationalists from its social news website last Wednesday. A message at the link for the "r/altright" subreddit attributed its ban to an impermissible "proliferation of personal and confidential information." Also last week, the crowdfunding website GoFundMe removed a campaign for a conservative author and self-described "researcher" on the internet conspiracy theory known as "pizzagate," which alleged with no evidence that Democrats were running a child sex ring out of a Washington, D.C., pizza shop. Brittany Pettibone had launched her GoFundMe campaign for a video podcast about "traditional values that once made Western Civilization great," including "love of one's own culture, race and country." GoFundMe spokesman Bobby Whithorne said in an email that Pettibone's campaign was removed because it violated the company's terms of service, which include rules against promoting hate, violence, harassment, discrimination, terrorism or "intolerance of any kind." Pettibone, who declined to be interviewed, tweeted that GoFundMe didn't specify how her campaign violated its terms of service. Hate speech and promoting violence have long been barred under the terms of service of internet and social media companies such as Twitter and Facebook. But in the months leading up to the contentious presidential election, the emergence of the "alt-right" and high-profile trolling campaigns like one targeting "Ghostbusters" star Leslie Jones thrust the issue to the forefront. In November, for instance, AppNexus announced that it removed Breitbart News from its online advertising network because it said the news outlet had violated its policy against hate speech. AppNexus, which connects buyers and sellers of online ad space," determined that Breitbart "deployed crude racial, ethnic, gender, and sexual slurs in a way that could incite violence or discrimination against minority groups," a spokesman said at the time. The crackdown isn't limited to far-right extremists. In August, Twitter said it had suspended some 360,000 accounts over the previous year for violating its policies banning the promotion of terrorism and violent extremism. But the company says the changes announced Tuesday are "unrelated to that and focused on abuse and harassment." Also on Tuesday, Twitter said it's creating a "safe search" feature that removes tweets with potentially sensitive content and tweets from blocked and muted accounts from search results. The tweets will still exist on Twitter if people look for them, but won't appear in general search results. Twitter is also making some replies less visible so only the most relevant conversations surface. Jennifer Grygiel, an assistant professor of communications at Syracuse University, said Twitter still relies too heavily on its users to root out and report abusive material. "I have a simple fix: Just hire a lot more humans," Grygiel said. Don Black, whose Stormfront website is one of the oldest and most popular internet forums for white nationalists, said PayPal, Facebook and Amazon have cancelled his accounts since he launched the site in 1995. Andew Anglin, founder of neo-Nazi website called The Daily Stormer, also has said on his site that PayPal permanently shut down his online payment account in 2015. "Nobody lasts very long on PayPal if you're pro-white, which is unfortunate because a lot of people want to use PayPal to donate money," said Black, who instead encourages his supporters to donate with bitcoin, an electronic currency. Leaders of the Anti-Defamation League and the Southern Poverty Law Center say they frequently communicate with online companies to flag users spreading hate on their sites. "This is a game that never seems to end," said the SPLC's Mark Potok. "It's a bit of a whack-a-mole thing." __ Kunzelman reported from Baton Rouge, Louisiana.

FILE - In this Tuesday, Oct. 13, 2015, file photo, the Twitter logo appears on a phone post on the floor of the New York Stock Exchange. Twitter says it is taking more steps to clamp down on hate speech and abuse on its social networking service, Tuesday, Feb. 7, 2017. The company says it is working to identify people who have been banned for abusive behavior and stop them from creating new accounts.(AP Photo/Richard Drew, File)

NEW YORK (AP) — Twitter announced Tuesday that it is expanding efforts to protect its users from abuse and harassment, the latest milestone in a broader, growing corporate campaign to crack down on online hate.

The social media giant said it has begun identifying people who have been banned for abusive behavior and it will stop them from creating new accounts. The company said its changes, which also include a new "safe search" feature, will be implemented in the coming weeks.

In July, Twitter banned conservative provocateur Milo Yiannopoulos, an editor of the right-wing news site Breitbart News, for "participating in or inciting targeted abuse of individuals." Twitter subsequently suspended the accounts of other prominent figureheads of the "alt-right" fringe movement, an amorphous mix of racism, white nationalism, xenophobia and anti-feminism.

Twitter has been under fire for failing to address hate and abuse on the site since its founding a decade ago. Balancing its reputation as a free speech haven has come into conflict with efforts to protect users.

Other internet companies have taken recent steps to curb abusive behavior and ban users who violate rules against promoting hate.

Reddit banned a forum for white nationalists from its social news website last Wednesday. A message at the link for the "r/altright" subreddit attributed its ban to an impermissible "proliferation of personal and confidential information."

Also last week, the crowdfunding website GoFundMe removed a campaign for a conservative author and self-described "researcher" on the internet conspiracy theory known as "pizzagate," which alleged with no evidence that Democrats were running a child sex ring out of a Washington, D.C., pizza shop. Brittany Pettibone had launched her GoFundMe campaign for a video podcast about "traditional values that once made Western Civilization great," including "love of one's own culture, race and country."

GoFundMe spokesman Bobby Whithorne said in an email that Pettibone's campaign was removed because it violated the company's terms of service, which include rules against promoting hate, violence, harassment, discrimination, terrorism or "intolerance of any kind." Pettibone, who declined to be interviewed, tweeted that GoFundMe didn't specify how her campaign violated its terms of service.

Hate speech and promoting violence have long been barred under the terms of service of internet and social media companies such as Twitter and Facebook. But in the months leading up to the contentious presidential election, the emergence of the "alt-right" and high-profile trolling campaigns like one targeting "Ghostbusters" star Leslie Jones thrust the issue to the forefront.

In November, for instance, AppNexus announced that it removed Breitbart News from its online advertising network because it said the news outlet had violated its policy against hate speech. AppNexus, which connects buyers and sellers of online ad space," determined that Breitbart "deployed crude racial, ethnic, gender, and sexual slurs in a way that could incite violence or discrimination against minority groups," a spokesman said at the time.

The crackdown isn't limited to far-right extremists. In August, Twitter said it had suspended some 360,000 accounts over the previous year for violating its policies banning the promotion of terrorism and violent extremism. But the company says the changes announced Tuesday are "unrelated to that and focused on abuse and harassment."

Also on Tuesday, Twitter said it's creating a "safe search" feature that removes tweets with potentially sensitive content and tweets from blocked and muted accounts from search results. The tweets will still exist on Twitter if people look for them, but won't appear in general search results.

Twitter is also making some replies less visible so only the most relevant conversations surface.

Jennifer Grygiel, an assistant professor of communications at Syracuse University, said Twitter still relies too heavily on its users to root out and report abusive material.

"I have a simple fix: Just hire a lot more humans," Grygiel said.

Don Black, whose Stormfront website is one of the oldest and most popular internet forums for white nationalists, said PayPal, Facebook and Amazon have cancelled his accounts since he launched the site in 1995. Andew Anglin, founder of neo-Nazi website called The Daily Stormer, also has said on his site that PayPal permanently shut down his online payment account in 2015.

Read More
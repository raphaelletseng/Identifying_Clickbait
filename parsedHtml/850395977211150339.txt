The earbuds of the future will let you control your phone with just the look on your face
The earbuds of the future will let you control your phone with just the look on your face
You can do just about anything with your smartphoneâ€”if you've got a free hand or two, of course. Sure, there've been great strides in accessibility features for those who can't control their phones by swiping around the touchscreen interface, like built-in AI assistants like Siri or Bixby and other hands-free control optionsâ€”but they depend on voice commands. Damon's wry smile could send out emoji using future earbud tech (not included in the Beats X buds pictured here). Image:  lili sams/mashable A project led by German PhD student Denys Matthies looks to give us even more hands-free control over our phones with new hardware that could send out your favorite ğŸ˜¬ Â emoji just by flashing a quick smile IRL. The tech, currently being tested in prototype form, is built into something you're probably already used to wearing for much of the day: earbuds. SEE ALSO: There's now an animated poop-emoji keyboard and we hope you're not eating right now The buds are outfitted with electrodes that can detect and identify different facial muscle movements from changes in the shape of a wearer's ear canal. Those readings are then used to send input commands to the phone. â€œWeâ€™re not trying to replace current input methods, just complement them,â€ Matthies said in an interview with . The facial sensing buds could potentially end up as an entirely new way to control your smartphone, using a mix of voice and touch commands and even AR camera  features. The current version of the prototype can detect five expressions at a 90 percent success rate: smiling, winking, turning the head to the right, opening the mouth, and making a â€œshhâ€ sound. It's not quite the entire range of human expressionâ€”what about the ğŸ™ƒ Â emoji?â€”but it's a start. The system's slightly less accurate when its wearers are on the move, boasting an 85.2 percent success rate. Matthies and his team have written at length about their work, and plan to present the prototype at the ACM CHI Conference on Human Factors in Computing Systems in Denver next month. There's no way to know if and when the tech could make its way to your favorite brand of earbudsâ€”and for now, Matthias told it's still just a research project. There's no word of any partnerships yet, or if the team will strike out on their own to create the buds themselves. But Matthies thinks the tech will be possible soonâ€”so when you walk by someone on the street wearing earbuds and grinning at nothing in particular in the future, there's a chance they're maybe just sending out a happy text. There are worse reasons to smile, after all. WATCH: This company is microchipping its workers to give them an all-access pass to the office

You can do just about anything with your smartphoneâ€”if you've got a free hand or two, of course.

Sure, there've been great strides in accessibility features for those who can't control their phones by swiping around the touchscreen interface, like built-in AI assistants like Siri or Bixby and other hands-free control optionsâ€”but they depend on voice commands.

Damon's wry smile could send out emoji using future earbud tech (not included in the Beats X buds pictured here). Image: lili sams/mashable

A project led by German PhD student Denys Matthies looks to give us even more hands-free control over our phones with new hardware that could send out your favorite ğŸ˜¬ emoji just by flashing a quick smile IRL. The tech, currently being tested in prototype form, is built into something you're probably already used to wearing for much of the day: earbuds.

The buds are outfitted with electrodes that can detect and identify different facial muscle movements from changes in the shape of a wearer's ear canal. Those readings are then used to send input commands to the phone.

â€œWeâ€™re not trying to replace current input methods, just complement them,â€ Matthies said in an interview with New Scientist. The facial sensing buds could potentially end up as an entirely new way to control your smartphone, using a mix of voice and touch commands and even AR camera features.

The current version of the prototype can detect five expressions at a 90 percent success rate: smiling, winking, turning the head to the right, opening the mouth, and making a â€œshhâ€ sound. It's not quite the entire range of human expressionâ€”what about the ğŸ™ƒ emoji?â€”but it's a start. The system's slightly less accurate when its wearers are on the move, boasting an 85.2 percent success rate.

Matthies and his team have written at length about their work, and plan to present the prototype at the ACM CHI Conference on Human Factors in Computing Systems in Denver next month.

There's no way to know if and when the tech could make its way to your favorite brand of earbudsâ€”and for now, Matthias told New Scientist it's still just a research project. There's no word of any partnerships yet, or if the team will strike out on their own to create the buds themselves.

But Matthies thinks the tech will be possible soonâ€”so when you walk by someone on the street wearing earbuds and grinning at nothing in particular in the future, there's a chance they're maybe just sending out a happy text. There are worse reasons to smile, after all.